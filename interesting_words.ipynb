{
  "metadata": {
    "name": "Interesting_Words",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003ch1 style\u003d\"text-align: center;\"\u003eInteresting Words\u003c/h1\u003e\n\u003ch2 style\u003d\"text-align: center;\"\u003eA project to identify interesting words within text\u003c/h2\u003e\n\u003cbr /\u003e\n\u003ch4 style\u003d\"text-align: center;\"\u003eBy Edmund Walsh\u003c/h4\u003e\n\u003cp style\u003d\"text-align: center;\"\u003e Oct 2020\u003c/p\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nThis project examines text files with the goal of indentifying \u0027interesting words\u0027. What is defined as interesting is highly dependent on context. For example, England at the widest part is about 311 miles from east to west which would make 311 miles interesting, but if we compare that to the width of the State of Texas in the U.S. which is about 773 miles, that number seems much less interesting. Therefore, we will begin this project by putting our example data into context. A quick examination of the data shows that our data of interest are speeches given by Barack Obama. Therefore to put this data into context we will add all available speeches given by past presidents to add context to our examination. This data comes from http://www.thegrammarlab.com/?nor-portfolio\u003dcorpus-of-presidential-speeches-cops-and-a-clintontrump-corpus.\n\nBeyond our examination of interesting words, the second goal of this project is to highlight how a project like this one can be set up and managed throughout the process. In short, any project like this requires coordination across many diciplines as we shall see and it also requires a set up from the start that will allow us to pursue the largest number of avenues in the future. We never know what we will encounter when getting into a project, but we always want to make sure the team is in the best position possible to tackle these future challenges."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nTo illustrate this idea, we can look at the graph to the right which shows a funnel process from left-to-right. Starting at the left, we begin any project with lots of ideas. Keeping those in mind we will need to coordinate across teams to make sure that the tools are available to address these ideas. In every project there will be ideas that are cut due to contraints or that simply don\u0027t work out, but we don\u0027t have the benefit of that knowledge until we try. That is why setting a wide filter at the start with a project managment style that will trim branches as the project continues will lead to the most success. In short, we want to give our team the best chances of success.\n\nIn this project we set out our project with some tools to aid us in this goal:\n1. Docker and Docker Compose\n    * Using containers allows us to separate services which allows team members to focus on different service areas and makes switching or scaling technology easier.\n2. Cassandra \u0026 Elasticsearch\n    * As our ultimate goal is to scale out this process, the Cassandra database provides robust tools at scale while also good support for graph analysis and elasticsearch. This seems to fit our purpose well and in combination with other tools we can get the best of a SQL and NoSQL perspective.\n3. Python and Spark\n    * This project will be focused on python, but we have set ourselves up for future success by incorporating Spark into the build. This should be very helpful when migrating from smaller examples to a larger context. Also, Spark SQL gives us the traditional functionalities of a SQL database and in combinatino with our NoSQL Cassandra is a \u0027best of both worlds\u0027 approach."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cimg src\u003d\"https://1.bp.blogspot.com/--WEcOzZZwdA/WXXJu1pUa2I/AAAAAAABEc8/dk130ND8o3gKOO3G3IbL5QLdZ6wnLBXrACEwYBhgL/s1600/Slide14.PNG\" \n    alt\u003d\"Project Funell\" style\u003d\"float: left; padding-left: 75px; height: 450px\" /\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nI now have a plan and a robust dataset. However, as this is just an initial look into the project there is no need to use all the data up front. Recall, I just want to set myself for easy future expansion. There is no need to tackle everything at once. Therefore, I only look at a smalle subsection of the data I have available. Since this speeches are from Barack Obama, I use all presidential speeches from Clinton, George Bush, George W. Bush, and Obama. \n\u003cbr /\u003e\n\u003cbr /\u003e\nDiving into the project, we being by importing the python packages we will use."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pendulum\nfrom cassandra.cluster import Cluster\nimport os\n\nimport nltk\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import plot_roc_curve\n%matplotlib inline"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nnltk.download(\"punkt\")\nnltk.download(\"maxent_ne_chunker\")\nnltk.download(\"universal_tagset\")\nnltk.download(\"stopwords\")\nnltk.download(\u0027averaged_perceptron_tagger\u0027)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nfrom nltk import regexp_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nThis project takes advantage of both the cassandra interpreter that I have set up in this notebok as well as the python cassandra driver. Below, I create the function that connects us via python to the database. From there I create the keyspace and tables (also known as column families in cassandra) that will hold our larger data."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n# define cassandra connection function\ndef create_session(host, port, db \u003d \u0027\u0027):\n    cluster \u003d Cluster([host],port\u003dport)\n    session \u003d cluster.connect(db,wait_for_all_pools\u003dTrue)\n    return(session)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%cassandra\nCREATE KEYSPACE IF NOT EXISTS iwords WITH replication \u003d {\u0027class\u0027: \u0027NetworkTopologyStrategy\u0027, \u0027DC1\u0027: \u00271\u0027}  AND durable_writes \u003d true;"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%cassandra\nCREATE TABLE IF NOT EXISTS iwords.raw (filename text, pres text, speech_title text, speech_dt timestamp, doc_num int, line_num int, text text, in_office boolean, PRIMARY KEY (filename, line_num));"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nI expect elasticsearch to be a helpful tool for this project. Therefore I am setting up a search index on the table I have just created. This will help me search the text data and find answers.\n\nThe output from the shell command below will sometimes come back with error message in the notebook, this is simply an artifact of the process, it is working. Please ignore and continue.\n\u003cbr /\u003e\nAfter that is created, I begin loading the data into the data process by connecting pythong to cassandra then parsing the raw text files. "
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\ncurl -XPUT -H \u0027Content-Type: application/json\u0027 http://172.29.0.2:9200/iwords -d\u0027{\"mappings\":{\"raw\":{\"discover\":\".*\"}}}\u0027 {\"acknowledged\":true, \"shards_acknowledged\":true,\"index\":\"raw\"}"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nsession \u003d create_session(\u0027172.29.0.2\u0027, 9042, \u0027iwords\u0027)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ndef date_check(dt_txt):\n    if dt_txt \u003d\u003d \u0027\u0027:\n        return(None)\n    else:\n        parsed_dt \u003d pendulum.parse(dt_txt, strict\u003dFalse)\n        return(parsed_dt)\n\n# define text parser for presidential speeches\ndef parse_ps(filename, name, doc_num, io_boo \u003d True):\n    with open(filename, \u0027r\u0027, encoding\u003d\u0027ISO-8859-1\u0027) as fobj:\n        raw_title \u003d fobj.readline()\n        parsed_title \u003d raw_title.strip().replace(\u0027\u003ctitle\u003d\u0027,\u0027\u0027).replace(\u0027\u003e\u0027,\u0027\u0027).replace(\u0027\"\u0027,\u0027\u0027).replace(\"\u0027\",\"\u0027\u0027\")\n        raw_date \u003d fobj.readline()\n        parsed_date_txt \u003d raw_date.strip().replace(\u0027\u003cdate\u003d\u0027,\u0027\u0027).replace(\u0027\u003e\u0027,\u0027\u0027).replace(\u0027\"\u0027,\u0027\u0027)\n        parsed_date \u003d date_check(parsed_date_txt)\n        counter \u003d 0\n        line0 \u003d fobj.readline()\n        while line0:\n            line1 \u003d line0.replace(\"\u0027\",\"\u0027\u0027\")\n            stmt \u003d \u0027\u0027\n            if (line1 !\u003d \u0027\u0027) \u0026 (line1.strip() !\u003d \u0027\u0027):\n                if parsed_date \u003d\u003d None:\n                    stmt \u003d \"\"\"INSERT INTO iwords.raw (filename, doc_num, line_num, pres, text, speech_title, in_office) VALUES (\u0027{}\u0027, {}, {}, \u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, {});\"\"\".format(filename, doc_num, counter, name, line1, parsed_title, io_boo)\n                else:\n                    stmt \u003d \"\"\"INSERT INTO iwords.raw (filename, doc_num, line_num, pres, text, speech_title, speech_dt, in_office) VALUES (\u0027{}\u0027, {}, {}, \u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, {});\"\"\".format(filename, doc_num, counter, name, line1, parsed_title, parsed_date, io_boo)\n                #print(stmt)\n                session.execute(stmt)\n            counter \u003d counter + 1\n            line0 \u003d fobj.readline()\n\n            "
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nfolder_root \u003d \u0027Presidential_Speeches\u0027\nspeeches_dir \u003d os.listdir(folder_root)\n\nfor d in speeches_dir:\n    pres_speeches \u003d folder_root + \u0027/\u0027 + d\n    speech_files \u003d os.listdir(pres_speeches)\n    speech_files.sort()\n    counter \u003d 0\n    for speech_file in speech_files:\n        speech_path \u003d pres_speeches + \u0027/\u0027 + speech_file\n        # line 1 is title\n        parse_ps(speech_path, d, counter)\n        counter \u003d counter + 1\n        \n        \n            \nprint(\"Raw Data Loaded Into Database\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "When starting the project, a quick visual examination of the text revealed that these were speeches given by Barak Obama. Now that the data is loaded, I want to take one example from our data of interest and compare it to the data we have added to make sure we aren\u0027t duplicating speeches.s\nTo do that I will use elasticsearch to search the speeches to see if our data of interest is included."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\ncurl -X GET \"http://172.29.0.2:9200/iwords/raw/_search?pretty\" -H \u0027Content-Type: application/json\u0027 -d \u0027{\"query\":{\"regexp\":{\"text\": \"Let me begin by saying thank.*\"}}}\u0027\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nWhat this reveals is that the presidential speeches I have added are not included in the data of interest. A deeper examination reveals that the reason for this is that the data of interest come from before Obama took office. This could prove interesting for our analysis and we can consider the data of interest speeches to represent \u0027candidate Obama\u0027 versus our added data to represent \u0027President Obama\u0027\n\u003cbr /\u003e\nNow that this is clear, we want to add our data of interest into our database which I will do below.\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nfolder_root \u003d \u0027doi\u0027\nspeech_files \u003d os.listdir(folder_root)\ndoi_dts \u003d [pendulum.parse(\"2007-02-10\"),pendulum.parse(\"2008-08-29\"),pendulum.parse(\"2006-06-14\"),pendulum.parse(\"2006-08-28\"),pendulum.parse(\"2006-11-20\"),pendulum.parse(\"2005-11-01\")]\ndoi_titles \u003d [\"Official Announcement of Candidacy for US President\",\"Acceptance Speech\",\"Remarks on Taking Back America\",\"Recollections of his father, while visiting Kenya\",\"Plan for Iraq War\",\"Non-Proliferation and Russia: The Challenges Ahead\"]\n\nspeech_files.sort()\nspeech_files"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nfor i in range(0,len(speech_files)):\n    title \u003d doi_titles[i]\n    dt \u003d doi_dts[i]\n    filename \u003d \u0027doi/\u0027 + speech_files[i]\n    counter \u003d 0\n    with open(filename, \u0027r\u0027, encoding\u003d\u0027ISO-8859-1\u0027) as fobj:\n        counter \u003d 0\n        line0 \u003d fobj.readline()\n        while line0:\n            line1 \u003d line0.replace(\"\u0027\",\"\u0027\u0027\")\n            stmt \u003d \"\"\"INSERT INTO iwords.raw (filename, doc_num, line_num, pres, text, speech_title, speech_dt, in_office) VALUES (\u0027{}\u0027, {}, {}, \u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, {});\"\"\".format(filename, i, counter, \u0027obama\u0027, line1, title, dt, False)\n            #print(stmt)\n            session.execute(stmt)\n            line0 \u003d fobj.readline()\n            counter \u003d counter + 1\n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nAt this point I have loaded all of our raw data that we plan to use thus far. However, as the data is in raw form it needs to be cleaned up for the analysis. First, I will create a new table called \u0027clean0\u0027 to represent the first attempt at cleaning. In future, I may want to compare how this approach performs relative to others (i.e. those would be named cleaned1, cleaned2, etc.).\n\u003cbr /\u003e\nTo perform this cleaning I will use the NLP basics of tokenization, stemming, removing stop words, and part of speech tagging. The approaches I use here are all rather text book but are tried and true methods. It may be possible to improve on these and we are well set up to do so in the future.\nnow that all data is added, create a new table for cleaned data, loop through by filename"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%cassandra\nCREATE TABLE IF NOT EXISTS iwords.clean0 (filename text, talk_time timestamp, pres text, party text, in_office boolean, word text, pos text, PRIMARY KEY (pres, talk_time)) ;\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\ncurl -XPUT -H \u0027Content-Type: application/json\u0027 http://172.29.0.2:9200/iwords -d\u0027{\"mappings\":{\"raw\":{\"discover\":\".*\"}}}\u0027 {\"acknowledged\":true, \"shards_acknowledged\":true,\"index\":\"clean0\"}"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nfile_nms_rows \u003d session.execute(\"SELECT DISTINCT filename FROM iwords.raw\")"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nfile_nms0 \u003d []\nfor row in file_nms_rows:\n    file_nms0.append(row.filename)\n    \n\nfile_nms \u003d np.array(file_nms0)\nlen(file_nms)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "One quick aside, you may notice that because we set up line number in our database as the partitioning part of our compound primary key, the text comes ordered. This is an example on how a good setup saves work in the future.\n\u003cbr /\u003e\nI will also add party affiliation to our data as this could be interesting for future analysis. I have also added a time variable which is based on the day of the speech and assuming the reader reads at a speed of about 200-250 words per minute. Again, this isn\u0027t something I will take full advantage of in this project but it does seem like an interesting variable to study in future."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nparty_aff \u003d [(\u0027obama\u0027, \u0027D\u0027), (\u0027clinton\u0027, \u0027D\u0027), (\u0027bush\u0027, \u0027R\u0027), (\u0027gwbush\u0027, \u0027R\u0027)]"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ndef run_cleaner0():\n    party_aff \u003d [(\u0027obama\u0027, \u0027D\u0027), (\u0027clinton\u0027, \u0027D\u0027), (\u0027bush\u0027, \u0027R\u0027), (\u0027gwbush\u0027, \u0027R\u0027)]\n\n    file_nms_rows \u003d session.execute(\"SELECT DISTINCT filename FROM iwords.raw\")\n    file_nms0 \u003d []\n    for row in file_nms_rows:\n        file_nms0.append(row.filename)\n\n\n    file_nms \u003d np.array(file_nms0)\n\n    for fnm in file_nms:\n        sub_stmt \u003d \"\"\"SELECT * FROM iwords.raw WHERE filename \u003d \u0027{}\u0027;\"\"\".format(fnm)\n        #print(\u0027sub\u0027)\n        #print(sub_stmt)\n        tmp_sub \u003d session.execute(sub_stmt)\n        #print(\u0027sub executed\u0027)\n        # pull each row and organize data\n        data \u003d []\n        for row in tmp_sub:\n            tmp \u003d {\n                \u0027filename\u0027: row.filename,\n                \u0027line_num\u0027: row.line_num,\n                \u0027doc_num\u0027: row.doc_num,\n                \u0027pres\u0027: row.pres,\n                \u0027speech_title\u0027: row.speech_title,\n                \u0027speech_dt\u0027: row.speech_dt,\n                \u0027in_office\u0027: row.in_office,\n                \u0027text\u0027: row.text\n            }\n            data.append(tmp)\n\n        # clean data\n        df0 \u003d pd.DataFrame(data)\n        #print(row.speech_dt)\n        time_input \u003d df0[\u0027speech_dt\u0027][0]\n        if time_input !\u003d None:\n            talk_time \u003d pendulum.parse(str(time_input))\n            pres \u003d df0[\u0027pres\u0027][0]\n            title \u003d df0[\u0027speech_title\u0027][0]\n            prty \u003d [p for n, p in party_aff if n \u003d\u003d pres][0]\n            io_val \u003d df0[\u0027in_office\u0027][0]\n            for txt_str in df0[\u0027text\u0027]:\n                sw_en \u003d stopwords.words(\u0027english\u0027)\n                stemming \u003d PorterStemmer()\n                pattern \u003d \"\\w+\"\n                #\\w+(?:\u0027\\w+)?|[^\\w\\s]\n                #arr \u003d nltk.word_tokenize(df0[\"text\"][0])\n                #list(map(lambda x: nltk.pos_tag(x, tagset\u003d\u0027universal\u0027, lang\u003d\u0027eng\u0027), arr))\n                arr0 \u003d regexp_tokenize(txt_str, pattern)\n                arr1 \u003d map(lambda x: stemming.stem(x), arr0)\n                arr2 \u003d [word for word in arr1 if word not in sw_en]\n                pos0 \u003d nltk.pos_tag(arr2, tagset\u003d\u0027universal\u0027, lang\u003d\u0027eng\u0027)\n                for word, pos in pos0:\n                    input_time \u003d str(talk_time)\n                    if(len(input_time) \u003e 30):\n                        input_time \u003d str(talk_time)[0:23]+\"+00:00\"\n                    else:\n                        input_time \u003d talk_time\n                    stmt \u003d \"\"\"INSERT INTO iwords.clean0 (filename, talk_time, pres, party, in_office, word, pos) VALUES (\u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, \u0027{}\u0027, {}, \u0027{}\u0027, \u0027{}\u0027);\"\"\".format(fnm, input_time, pres, prty, io_val, word, pos)\n                    #print(stmt)\n                    session.execute(stmt)\n                    talk_time \u003d talk_time.add(seconds\u003d0.26)\n            \n        "
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nrun_cleaner0()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nAt this point, the data is cleaned and ready for analysis. So back to our question, what is an interesting word. Given that we have added the context I think one question that we should look at are the words that differentiate Canadidate Obama from President Obama. Below I pull the text available from each and make a comparision. In short, an interesting word is one that allows us to tell if the speech is from Candidate Obama or President Obama."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ncbama_rows \u003d session.execute(\"SELECT word FROM iwords.clean0 WHERE pres \u003d \u0027obama\u0027 AND in_office \u003d False ALLOW FILTERING;\")\nobama_rows \u003d session.execute(\"SELECT word FROM iwords.clean0 WHERE pres \u003d \u0027obama\u0027 AND in_office \u003d True ALLOW FILTERING;\")"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ncbama_words \u003d []\nfor row in cbama_rows:\n    if len(row.word) \u003e 3:\n        cbama_words.append(row.word)\n    \n    \nobama_words \u003d []\nfor row in obama_rows:\n    if len(row.word) \u003e 3:\n        obama_words.append(row.word)\n        \nlen(obama_words)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nplt.figure(figsize\u003d(10,8))\nplt.title(\"Frequency Distribution of Candidate Obama\")\nobama_fdist \u003d nltk.FreqDist(obama_words)\n# \nobama_pdist \u003d [(k, v*100/len(obama_words)) for k,v in obama_fdist.items()]\n\ncbama_fdist \u003d nltk.FreqDist(cbama_words)\n# \ncbama_pdist \u003d [(k, v*100/len(cbama_words)) for k,v in cbama_fdist.items()]\ncbama_fdist.plot(50, cumulative\u003dFalse)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nplt.figure(figsize\u003d(10,8))\nplt.title(\"Frequency Distribution of President Obama\")\n\nobama_fdist.plot(50, cumulative\u003dFalse)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nComparing the frequency distribution of the words Candidate Obama uses versus those that President Obama uses highlight some stark differences. It definitely appearch that his vocabulary changed. One other point of note is that in the President Obama distribution, applause rank extremely high. It is likely that this is applause being noted in the speech coming from the crowd, not that he was saying \u0027applause\u0027 a lot. While I won\u0027t tackle this now, it is definitely something that should be addressed for future work.\n\u003cbr /\u003e\nTo make a clearer comparison we should look at how often the word gets used side by side. One issue is that President Obama made many more speeches (or at least our data is much larger for that) and we will need to adjust. Therefore below, I look at how often the word is used given the total number of words in our database for each version of Obama (Candidate/President)."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ncbama_wdat \u003d []\nfor tup in cbama_pdist:\n    tmp \u003d {\n        \u0027word\u0027: tup[0],\n        \u0027cbama_pdist\u0027: tup[1]\n    }\n    cbama_wdat.append(tmp)\n    \n    \ncbama_df \u003d pd.DataFrame(cbama_wdat)\n\nobama_wdat \u003d []\nfor tup in obama_pdist:\n    tmp \u003d {\n        \u0027word\u0027: tup[0],\n        \u0027obama_pdist\u0027: tup[1]\n    }\n    obama_wdat.append(tmp)\n    \nobama_df \u003d pd.DataFrame(obama_wdat)\n    \ndfs \u003d [cbama_df, obama_df]\ndf1 \u003d pd.merge(cbama_df, obama_df, how\u003d\u0027inner\u0027, on\u003d\u0027word\u0027)\ndf1[\u0027diff\u0027] \u003d df1[\u0027cbama_pdist\u0027] - df1[\u0027obama_pdist\u0027]\ndf1.sort_values(by\u003d[\u0027diff\u0027]).iloc[:10,:]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nAbove we compare the top words used by President Obama, relative to Candidate Obama using those same words. Some increased substantially even though they had been used heavily by Candidate Obama. For example people we use heavily by both, but President Obama used in about 1% of the time for all words. In contrast, Candidate Obama didn\u0027t use Congress very often but trebled his use after becoming president.\n\u003cbr /\u003e\nBelow we look at the flip side, which words were used by Candidate Obama more than president Obama. What really stands out here to me is the sentiment of these words. It seems rather clear that Candidate Obama was much more negative in sentiment than President Obama."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ndf1.sort_values(by\u003d[\u0027diff\u0027], ascending\u003dFalse).iloc[:10,:]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Below, I perform a similar analysis looking at while Being President only, to see if President Obama is much different than his peers."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\npres_rows \u003d session.execute(\"SELECT word, pres FROM iwords.clean0 WHERE in_office \u003d True ALLOW FILTERING;\")"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nobama_pres_words \u003d []\nnonobama_pres_words \u003d []\nfor row in pres_rows:\n    if len(row.word) \u003e 3:\n        if row.pres \u003d\u003d \u0027obama\u0027:\n            obama_pres_words.append(row.word)\n        else:\n            nonobama_pres_words.append(row.word)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nplt.figure(figsize\u003d(10,8))\nplt.title(\"Frequency Distribution of President Obama\")\nobama_pres_fdist \u003d nltk.FreqDist(obama_pres_words)\n# \nobama_pres_pdist \u003d [(k, v*100/len(obama_pres_words)) for k,v in obama_pres_fdist.items()]\n\nnonobama_pres_fdist \u003d nltk.FreqDist(nonobama_pres_words)\n# \nnonobama_pres_pdist \u003d [(k, v*100/len(nonobama_pres_words)) for k,v in nonobama_pres_fdist.items()]\nobama_pres_fdist.plot(50, cumulative\u003dFalse)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nplt.figure(figsize\u003d(10,8))\nplt.title(\"Frequency Distribution of Other Recent Presidents\")\nnonobama_pres_fdist.plot(50, cumulative\u003dFalse)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nobama_pres_wdat \u003d []\nfor tup in obama_pres_pdist:\n    tmp \u003d {\n        \u0027word\u0027: tup[0],\n        \u0027obama_pres_pdist\u0027: tup[1]\n    }\n    obama_pres_wdat.append(tmp)\n    \n    \nobama_pres_df \u003d pd.DataFrame(obama_pres_wdat)\n\nnonobama_pres_wdat \u003d []\nfor tup in nonobama_pres_pdist:\n    tmp \u003d {\n        \u0027word\u0027: tup[0],\n        \u0027nonobama_pres_pdist\u0027: tup[1]\n    }\n    nonobama_pres_wdat.append(tmp)\n    \nnonobama_pres_df \u003d pd.DataFrame(nonobama_pres_wdat)\n    \ndf2 \u003d pd.merge(obama_pres_df, nonobama_pres_df, how\u003d\u0027inner\u0027, on\u003d\u0027word\u0027)\ndf2[\u0027pres_diff\u0027] \u003d df2[\u0027obama_pres_pdist\u0027] - df2[\u0027nonobama_pres_pdist\u0027]\ndf2.sort_values(by\u003d[\u0027pres_diff\u0027]).iloc[:10,:]"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ndf2.sort_values(by\u003d[\u0027pres_diff\u0027], ascending\u003dFalse).iloc[:10,:]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nThe differences here are less stark, but there are some interesting differences on topics and themes especially national themes that deserve more study. One thing is clear, Obama tends to get more applause it seems.\n\u003cbr /\u003e\nAt this point we have a simple answer to the question at hand at what represents an interesting word. However, we should add another perspective. Can we use these difference to predict whether any given speech is from either Candidate or President Obama. Below we set up the data to answer this question and add another perspective to which words are interesting.\n\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ncbama_rows \u003d session.execute(\"SELECT word, pos, in_office, talk_time FROM iwords.clean0 WHERE pres \u003d \u0027obama\u0027 AND in_office \u003d False ALLOW FILTERING;\")\nobama_rows \u003d session.execute(\"SELECT word, pos, in_office, talk_time FROM iwords.clean0 WHERE pres \u003d \u0027obama\u0027 AND in_office \u003d True ALLOW FILTERING;\")\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ncbama_data \u003d []\nfor row in cbama_rows:\n    if len(row.word) \u003e 3:\n        tmp \u003d {\n            \u0027word\u0027: row.word,\n            \u0027pos\u0027: row.pos,\n            \u0027in_office\u0027: row.in_office,\n            \u0027talk_time\u0027: row.talk_time\n        }\n        cbama_data.append(tmp)\n    \n    \nobama_data \u003d []\nfor row in obama_rows:\n    if len(row.word) \u003e 3:\n        tmp \u003d {\n            \u0027word\u0027: row.word,\n            \u0027pos\u0027: row.pos,\n            \u0027in_office\u0027: row.in_office,\n            \u0027talk_time\u0027: row.talk_time\n        }\n        obama_data.append(tmp)\n        \n\ncbama_data_df \u003d pd.DataFrame(cbama_data)\nobama_data_df \u003d pd.DataFrame(obama_data)\nobama_data_df.head()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ncbama_ddf1 \u003d pd.merge(cbama_df, cbama_data_df, how\u003d\u0027inner\u0027, on\u003d\u0027word\u0027)\ncbama_ddf1 \u003d cbama_ddf1.rename(columns\u003d{\u0027cbama_pdist\u0027: \u0027pdist\u0027})\ntmp \u003d cbama_ddf1[\"talk_time\"] - min(cbama_ddf1[\"talk_time\"])\ncbama_ddf1[\u0027talk_time\u0027] \u003d [t.value for t in tmp]\ncbama_ddf1[\u0027in_office\u0027] \u003d (cbama_ddf1[\u0027in_office\u0027]*1 - 1 ) * -1\ncbama_ddf1.head()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nobama_ddf1 \u003d pd.merge(obama_df, obama_data_df, how\u003d\u0027inner\u0027, on\u003d\u0027word\u0027)\nobama_ddf1 \u003d obama_ddf1.rename(columns\u003d{\u0027obama_pdist\u0027: \u0027pdist\u0027})\ntmp \u003d obama_ddf1[\"talk_time\"] - min(cbama_ddf1[\"talk_time\"])\nobama_ddf1[\u0027talk_time\u0027] \u003d [t.value for t in tmp]\nobama_ddf1[\u0027in_office\u0027] \u003d (obama_ddf1[\u0027in_office\u0027]*1 - 1 ) * -1\nobama_ddf1.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nAbove we have created a dataset that sets out our target variable of whether Obama was in office as a binary classification problem. We also have the part of speech, the frequency of the term relative to total number of words, and the time since our first candidate obama speech. Below we wil use One Hot Encoding for the word and part of speech and scale. I will only work with a random subset of the data for now."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nn_size\u003d1000\nframe \u003d [cbama_ddf1.sample(n\u003dn_size), obama_ddf1.sample(n\u003dn_size*2)]\nddf2 \u003d pd.concat(frame)\nlen(ddf2)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nohe_arr \u003d np.array(ddf2.loc[:,[\u0027word\u0027,\u0027pos\u0027]])\nother_arr \u003d np.array(ddf2.loc[:, [\u0027in_office\u0027,\u0027pdist\u0027]])\nenc \u003d OneHotEncoder(drop\u003d\u0027first\u0027)\nohe_fitted \u003d enc.fit(ohe_arr)\nenc_cols \u003d ohe_fitted.transform(ohe_arr).toarray()\npreproc_data \u003d np.concatenate([other_arr, enc_cols], axis\u003d1)\npreproc_df \u003d pd.DataFrame(preproc_data)\ncol_nms \u003d np.hstack(np.concatenate([np.array([\u0027in_office\u0027,\u0027pdist\u0027]), enc.get_feature_names([\u0027word\u0027,\u0027pos\u0027])]))\npreproc_df.columns \u003d list(col_nms)\nsample_ids \u003d np.random.choice(n_size*3, replace \u003d False, size \u003d n_size) \ntest_mat \u003d pd.DataFrame(preproc_df).iloc[sample_ids,:]\ntrain_mat \u003d pd.DataFrame(preproc_df).iloc[-sample_ids,:]\ntrain_mat.head()\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nX_train \u003d train_mat.loc[:,list(col_nms[1:])]\ny_train \u003d train_mat.loc[:,col_nms[0]]\nX_test \u003d test_mat.loc[:,col_nms[1:]]\ny_test \u003d test_mat.loc[:,col_nms[0]]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nTo model this classification, I will use a logistic model with regularization. I chose this model for a few simple reasons. First, logistic regression is probably the benchmark model in classification problems. It is usually best to start with something tried and true. Extending it to use Elastic Net adds a Machine Learning component. It also makes sense to keep the number of features down and to not over-weight any particular word. Furthermore, I have had good personal experience with this approach and tend to favor as a place to start and compare to."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nclf \u003d SGDClassifier(random_state \u003d 0, loss\u003d\u0027log\u0027, penalty\u003d\u0027elasticnet\u0027)\nclf.fit(X_train, y_train)\n\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ny_train_pred \u003d cross_val_predict(clf, X_train, y_train, cv\u003d10)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ntn, fp, fn, tp \u003d confusion_matrix(y_train, y_train_pred).ravel()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n# The Negative Class\n\"\"\"{} True Positives and {} False Positives\"\"\".format(tp,fp)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n# The Positive Class\n\"\"\"{} False negatives and {} True Negatives\"\"\".format(fn,tn)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n\"\"\"{:,.2F} Precision\"\"\".format(precision_score(y_train,y_train_pred))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n\"\"\"{:,.2F} Recall\"\"\".format(recall_score(y_train,y_train_pred))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n#plt.figure(figsize\u003d(50,50))\nplot_roc_curve(clf, X_test, y_test)\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nAbove we can see that our first modelling attempt shows decent but not great performance, it tends to mis-identify more than half, but given it is our first attempt this isn\u0027t a bad benchmark to build off of. As was the purpose of this project, it is more important to notice we are well set up for future improvement and pursuing other ideas.\n\u003cbr /\u003e\nBelow we can see first which words when said tend to predict that President Obama said them (of course applause is still suspicious) and then to the right which words when said tend to predict they were said by Candidate Obama."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nsol_df \u003d pd.DataFrame({\u0027coefs\u0027: clf.coef_[0],\u0027abs_coefs\u0027: clf.coef_[0], \u0027variables\u0027: col_nms[1:]})\nsol_df.sort_values(\u0027abs_coefs\u0027).iloc[:10,:]"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\nsol_df.sort_values(\u0027coefs\u0027, ascending\u003dFalse).iloc[:10,:]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr /\u003e\nBring our project to a close, I will choose a few words I found the most interesting given the information above and give some examples of sentences where they are found. This is not meant to be exhaustive only highlight what I have found thus far. Below I present some tools to aid me. First an elasticsearch of the terms as well as our frequency distribution. The three words I will highlight are:\n\n1. promise\n    * It tends to be one of the most predictive words from our machine learning model\n2. Iraq\n    * It shows up in both approaches (word count and machine learning) as an important and interesting word\n3. corrupt\n    * While not included in the machine learning model, Candidate Obama used this word regularly although not a lot but Presdient Obama used this word almost never. An interesting change."
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\ncurl -X GET \"http://172.29.0.2:9200/iwords/raw/_search?pretty\" -H \u0027Content-Type: application/json\u0027 -d \u0027{\n    \"query\":{\n        \"bool\":{\n            \"should\":[\n                {\"regexp\":\n                    {\"text\": \".*corrupt.*\"}\n                },\n                {\"regexp\":\n                    {\"pres\": \"obama\"}\n                },\n                {\"match\":\n                    {\"in_office\": false}\n                }\n                ]\n            \n        }}}\u0027"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\ntarget \u003d \"corrupt\"\n[(k,v) for k,v in cbama_fdist.items() if k \u003d\u003d target]"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\niw_all \u003d []\niw1 \u003d {\n    \"Word(Total Occurances)\": \"promise(41)\",\n    \"Documents\": \"doc1.txt,doc2.txt\",\n    \"Sentences containing the word\": \"Let\u0027s protect the hard-earned benefits their companies have promised. \\n After all, every four years, candidates from both parties make similar promises, and I expect this year will be no different. \\n It is that promise that has always set this country apart - that through hard work and sacrifice, each of us can pursue our individual dreams but still come together as one American family, to ensure that the next generation can pursue their dreams as well.\\n\"\n}\n\niw2 \u003d {\n    \"Word(Total Occurances)\": \"iraq(63)\",\n    \"Documents\": \"doc1.txt,doc2.txt,doc3.txt,doc5.txt\",\n    \"Sentences containing the word\": \"And when all else fails, when Katrina happens, or the death toll in Iraq mounts, we\u0027ve been told that our crises are somebody else\u0027s fault. We\u0027re distracted from our real failures, and told to blame the other party, or gay people, or immigrants.\\n A few Tuesdays ago, the American people embraced this seriousness with regards to Americaâs policy in Iraq. We\u0027ve seen our children leave for Iraq and terrorists threaten to finish the job they started on 9/11.\\n\"\n}\n\niw3 \u003d {\n    \"Word(Total Occurances)\": \"corrupt(23)\",\n    \"Documents\": \"doc3.txt,doc4.txt\",\n    \"Sentences containing the word\": \"In a century just six years old, our faith has been shaken by war and terror, disaster and despair, threats to the middle-class dream, and scandal and corruption in our government.\\n But while corruption is a problem we all share, here in Kenya it is a crisis - a crisis that\u0027s robbing an honest people of the opportunities they have fought for - the opportunity they deserve.\\n And yet, the reason I speak of the freedom that you fought so hard to win is because today that freedom is in jeopardy. It is being threatened by corruption.\\n\"\n}\n\niw_all.append(iw1)\niw_all.append(iw2)\npd.DataFrame(iw_all)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Conclusion\nThis project highlights the approach and management of an NLP project. Along the way we are able to identify some interesting words within their context and perhaps more important, we have set the project up for expansion and scaling in the future.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    }
  ]
}